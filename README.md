# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
Here we are leveraging machine learning to perform a classification and predict when a Term Deposit will be opend or not by the potential customer.
Dataset has various personal info about the employee and his past expereince with Term Deposit. We seek to predict if he will open a Term Deposit or Not

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
AutoML Model outperfromed the model trained with the help of Hyperdrive. The reason could be the parameter sample space 
given to hyperdrive and also AutoML was able to try out several diffrent models while in our Hyperdrive experiment we were using 
only Logistic Regression model 
## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
1. The Architecture consist of a Training Script (train.py) that has three main section
-- Loading Data from URL using TabularDatasetFactory
-- Cleaning the data using the custom Clean Method Provided
-- Spliting and training the Model using Logistic Regression model from SK Learn Library.
2. We have a SK Learn Estimator where we load the train.py file as well as compute to run experiment on.
3. We Create a Hyperdrive Config File with RandomParemeterSampling for a parameter space consisting of (max_iter,--C ) variables that are to be optimised and Bandit Policy is used as an Early stoping policy
**What are the benefits of the parameter sampler you chose?**
We have taken the most primitive approch of randomly trying out diffrent combinations to reach the best result. We could have taken Bayesian Sampling which can coverge faster.
**What are the benefits of the early stopping policy you chose?**
The main benifit of Bandit policy is that it helps us get an idea when we are not improving the model or performing worse hence saves resorces which other wise may get wasted in trying to improve the model when its not !!
## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up

**Image of cluster marked for deletion**
--Attached the image of the code for deleting cluster in the git repoistory "Cluster Marked for Deletion.PNG"

